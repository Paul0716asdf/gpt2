{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import GPT2LMHeadModel\nfrom transformers import GPT2Tokenizer , BertTokenizer, GPT2PreTrainedModel, GPT2Model, GPT2Config, GPT2LMHeadModel\nimport torch\nfrom typing import Optional, Tuple\nimport pandas as pd\nimport numpy as np\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import Dataset\nfrom typing import*\nfrom torch import tensor\n\nPRETRAINED_MODEL_NAME = \"gpt2\"\nPadding_id = 50256\nDEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") ","metadata":{"execution":{"iopub.status.busy":"2023-08-22T18:33:33.528622Z","iopub.execute_input":"2023-08-22T18:33:33.529013Z","iopub.status.idle":"2023-08-22T18:33:46.035622Z","shell.execute_reply.started":"2023-08-22T18:33:33.528979Z","shell.execute_reply":"2023-08-22T18:33:46.034515Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/asdfffff/SQuAD.csv\", index_col=0)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T18:43:22.627766Z","iopub.execute_input":"2023-08-22T18:43:22.628117Z","iopub.status.idle":"2023-08-22T18:43:23.764156Z","shell.execute_reply.started":"2023-08-22T18:43:22.628088Z","shell.execute_reply":"2023-08-22T18:43:23.763164Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"len(df_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T18:43:25.991392Z","iopub.execute_input":"2023-08-22T18:43:25.991755Z","iopub.status.idle":"2023-08-22T18:43:25.999607Z","shell.execute_reply.started":"2023-08-22T18:43:25.991725Z","shell.execute_reply":"2023-08-22T18:43:25.998637Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"100000"},"metadata":{}}]},{"cell_type":"code","source":"df_train = df_train[df_train['text'].isna() == False]","metadata":{"execution":{"iopub.status.busy":"2023-08-22T18:43:28.239057Z","iopub.execute_input":"2023-08-22T18:43:28.239585Z","iopub.status.idle":"2023-08-22T18:43:28.280164Z","shell.execute_reply.started":"2023-08-22T18:43:28.239546Z","shell.execute_reply":"2023-08-22T18:43:28.279212Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-22T18:43:29.416856Z","iopub.execute_input":"2023-08-22T18:43:29.417502Z","iopub.status.idle":"2023-08-22T18:43:29.431714Z","shell.execute_reply.started":"2023-08-22T18:43:29.417471Z","shell.execute_reply":"2023-08-22T18:43:29.430652Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"                      index  \\\n0  56be85543aeaaa14008c9063   \n1  56be85543aeaaa14008c9065   \n2  56be85543aeaaa14008c9066   \n3  56bf6b0f3aeaaa14008c9601   \n4  56bf6b0f3aeaaa14008c9602   \n\n                                            question  \\\n0           When did Beyonce start becoming popular?   \n1  What areas did Beyonce compete in when she was...   \n2  When did Beyonce leave Destiny's Child and bec...   \n3      In what city and state did Beyonce  grow up?    \n4         In which decade did Beyonce become famous?   \n\n                                             context                 text  \\\n0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...    in the late 1990s   \n1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...  singing and dancing   \n2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...                 2003   \n3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...       Houston, Texas   \n4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...           late 1990s   \n\n   answer_start  c_id  \n0         269.0     0  \n1         207.0     0  \n2         526.0     0  \n3         166.0     0  \n4         276.0     0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>question</th>\n      <th>context</th>\n      <th>text</th>\n      <th>answer_start</th>\n      <th>c_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>56be85543aeaaa14008c9063</td>\n      <td>When did Beyonce start becoming popular?</td>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>in the late 1990s</td>\n      <td>269.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>56be85543aeaaa14008c9065</td>\n      <td>What areas did Beyonce compete in when she was...</td>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>singing and dancing</td>\n      <td>207.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>56be85543aeaaa14008c9066</td>\n      <td>When did Beyonce leave Destiny's Child and bec...</td>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>2003</td>\n      <td>526.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56bf6b0f3aeaaa14008c9601</td>\n      <td>In what city and state did Beyonce  grow up?</td>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>Houston, Texas</td>\n      <td>166.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>56bf6b0f3aeaaa14008c9602</td>\n      <td>In which decade did Beyonce become famous?</td>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>late 1990s</td>\n      <td>276.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_train['text'] = df_train['text'].apply(lambda x : str(' ') + str(x) )\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-22T18:43:36.179758Z","iopub.execute_input":"2023-08-22T18:43:36.180124Z","iopub.status.idle":"2023-08-22T18:43:36.235819Z","shell.execute_reply.started":"2023-08-22T18:43:36.180096Z","shell.execute_reply":"2023-08-22T18:43:36.234683Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"                      index  \\\n0  56be85543aeaaa14008c9063   \n1  56be85543aeaaa14008c9065   \n2  56be85543aeaaa14008c9066   \n3  56bf6b0f3aeaaa14008c9601   \n4  56bf6b0f3aeaaa14008c9602   \n\n                                            question  \\\n0           When did Beyonce start becoming popular?   \n1  What areas did Beyonce compete in when she was...   \n2  When did Beyonce leave Destiny's Child and bec...   \n3      In what city and state did Beyonce  grow up?    \n4         In which decade did Beyonce become famous?   \n\n                                             context                  text  \\\n0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...     in the late 1990s   \n1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   singing and dancing   \n2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...                  2003   \n3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...        Houston, Texas   \n4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...            late 1990s   \n\n   answer_start  c_id  \n0         269.0     0  \n1         207.0     0  \n2         526.0     0  \n3         166.0     0  \n4         276.0     0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>question</th>\n      <th>context</th>\n      <th>text</th>\n      <th>answer_start</th>\n      <th>c_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>56be85543aeaaa14008c9063</td>\n      <td>When did Beyonce start becoming popular?</td>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>in the late 1990s</td>\n      <td>269.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>56be85543aeaaa14008c9065</td>\n      <td>What areas did Beyonce compete in when she was...</td>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>singing and dancing</td>\n      <td>207.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>56be85543aeaaa14008c9066</td>\n      <td>When did Beyonce leave Destiny's Child and bec...</td>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>2003</td>\n      <td>526.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56bf6b0f3aeaaa14008c9601</td>\n      <td>In what city and state did Beyonce  grow up?</td>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>Houston, Texas</td>\n      <td>166.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>56bf6b0f3aeaaa14008c9602</td>\n      <td>In which decade did Beyonce become famous?</td>\n      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n      <td>late 1990s</td>\n      <td>276.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_train = df_train.iloc[0:1000]","metadata":{"execution":{"iopub.status.busy":"2023-08-22T18:43:47.369416Z","iopub.execute_input":"2023-08-22T18:43:47.369758Z","iopub.status.idle":"2023-08-22T18:43:47.376272Z","shell.execute_reply.started":"2023-08-22T18:43:47.369730Z","shell.execute_reply":"2023-08-22T18:43:47.374611Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def my_pad_sequence(\n    sequences: Union[tensor, List[tensor]],\n    batch_first: bool = False,\n    padding_value: int = 0,\n    pos: str = 'right',\n) -> tensor:\n\n    if pos == 'right':\n        padded_sequence = torch._C._nn.pad_sequence(sequences, batch_first, padding_value)\n    elif pos == 'left':\n        sequences = tuple(map(lambda s: s.flip(0), sequences))\n        padded_sequence = torch._C._nn.pad_sequence(sequences, batch_first, padding_value)\n        _seq_dim = padded_sequence.dim()\n        padded_sequence = padded_sequence.flip(-_seq_dim+batch_first)\n    else:\n        raise ValueError(\"pos should be either 'right' or 'left', but got {}\".format(pos))\n    return padded_sequence\n\n\ndef QA_collate_batch(sample): #sample is List\n    input_ids_batch = [s[0] for s in sample]\n    label_batch = [s[1] for s in sample]\n\n    input_ids_batch = my_pad_sequence(input_ids_batch, batch_first=True, padding_value = Padding_id, pos='left')\n    label_batch = my_pad_sequence(label_batch, batch_first=True, padding_value = -100, pos='right')\n    attn_batch = (input_ids_batch != Padding_id).int()\n\n    return input_ids_batch, attn_batch, label_batch\n\n\nclass QAdataset(Dataset):\n    def __init__(self, df, tokenizer):\n        self.tokenizer = tokenizer\n        self.df = df\n    \n    def __getitem__(self, index):\n        df = self.df\n        EC = self.tokenizer.encode_plus('context :' + df['context'][index] + 'question :' + df['question'][index] + 'answer :')\n        input_ids = torch.tensor(EC['input_ids'], dtype=torch.long)\n        \n        ## ECl = self.tokenizer.encode_plus(df['label'][index])\n        ECl = self.tokenizer.encode_plus(df['text'][index])\n        label = torch.tensor(ECl['input_ids'], dtype=torch.long)\n\n        return input_ids, label\n    \n    def __len__(self):\n        return len(self.df)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T18:43:53.002899Z","iopub.execute_input":"2023-08-22T18:43:53.003410Z","iopub.status.idle":"2023-08-22T18:43:53.025716Z","shell.execute_reply.started":"2023-08-22T18:43:53.003359Z","shell.execute_reply":"2023-08-22T18:43:53.024580Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"tokenizer = GPT2Tokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\ntokenizer.pad_token_id = Padding_id","metadata":{"execution":{"iopub.status.busy":"2023-08-22T18:43:59.649196Z","iopub.execute_input":"2023-08-22T18:43:59.649660Z","iopub.status.idle":"2023-08-22T18:44:00.861023Z","shell.execute_reply.started":"2023-08-22T18:43:59.649618Z","shell.execute_reply":"2023-08-22T18:44:00.860014Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"955083372104459b8c766e4fd1080325"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4aa0b3fb7d96462bb837789cc69ef271"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c655da996b544eb3a3d9fee04f6489cf"}},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd \nfrom IPython.display import clear_output\nfrom torch.utils.data import DataLoader\nimport random\n\nBatch_size = 4\nFile_path = \"/kaggle/input/asdfffff/SQuAD.csv\"\n\ndf = df_train\nds = QAdataset(df, tokenizer) \ndataloader = DataLoader(ds, batch_size=Batch_size, shuffle=True, collate_fn=QA_collate_batch)","metadata":{"execution":{"iopub.status.busy":"2023-08-22T18:44:02.833513Z","iopub.execute_input":"2023-08-22T18:44:02.833970Z","iopub.status.idle":"2023-08-22T18:44:02.841865Z","shell.execute_reply.started":"2023-08-22T18:44:02.833883Z","shell.execute_reply":"2023-08-22T18:44:02.840988Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"class MyModel(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        model = GPT2LMHeadModel.from_pretrained(PRETRAINED_MODEL_NAME)\n        self.transformer = model.transformer\n        self.lm_head = model.lm_head\n        self.config = self.transformer.config\n        # self.lm_head = torch.nn.Linear(self.config.n_embd, self.config.vocab_size, bias=False)\n    \n    def forward(self,\n                input_ids,\n                attention_mask,\n                past_key_values: Optional[Tuple[Tuple[torch.Tensor]]] = None,\n                encoder_hidden_states: Optional[torch.Tensor] = None,\n                encoder_attention_mask: Optional[torch.FloatTensor] = None,\n                labels: Optional[torch.LongTensor] = None,\n                ) :\n\n        if labels is not None :\n            predict_logits = self.trainmode(input_ids=input_ids,\n                                            attention_mask=attention_mask,\n                                            labels=labels\n                                            )\n            predict_words = predict_logits.argmax(dim=-1)  ## batch, predict_length\n            \n#             print(predict_words.size())'\n#             print(labels.size())\n            \n#             print(tokenizer.convert_ids_to_tokens(predict_words[0]))\n#             print(tokenizer.convert_ids_to_tokens(labels[0]))\n            \n            lossfn = torch.nn.CrossEntropyLoss()\n            loss = lossfn(predict_logits.view(-1, predict_logits.size(-1)), labels.view(-1))\n\n        return loss\n    \n    \n    def trainmode(self,\n                  input_ids,\n                  attention_mask,\n                  labels: Optional[torch.LongTensor] = None, ## batch, seqlen\n                  ):\n        padding_token_id = self.config.pad_token_id\n        \n        predict_logits = []\n        \n        batch_size = input_ids.size()[0]\n        should_pred_len = labels.size()[1]\n        curlen = 0\n\n        unfinished_sentence = torch.tensor([1] * batch_size) ## batch_size\n        ### when first run the sentence, there is no past_key_values\n        ### so need the past_key_values for the setence, and then predict later\n        \n        input_ids = input_ids.to(DEVICE)\n        attention_mask = attention_mask.to(DEVICE)\n        transformer_outputs = self.transformer(\n            input_ids = input_ids,\n            attention_mask = attention_mask\n        )\n        input_ids = input_ids.cpu()\n        attention_mask = attention_mask.cpu()\n\n        #### the three need return is (1)last_hidden (2)logits (3)past_key_values\n\n        last_hidden = transformer_outputs.last_hidden_state ## batch size, seq_length, tensor_size\n        logits = self.lm_head(last_hidden).cpu()  ## batch size, seq_length, vacabulary size\n        last_hidden = last_hidden.cpu()\n        past_key_values = transformer_outputs.past_key_values  ## layer, 2, batchsize, num_head, seq_len, one_head_len\n\n        \n        ##check print(labels)\n        \n        #### predict the label\n        this_peer_finished = False\n        while this_peer_finished == False:\n\n            #### chose the predict logits from pre round #######################################################\n            ####################################################################################################\n            #### the logits_from_pre_step must not \"all is eos\"\n            logits_from_pre_step = logits[:,-1,:]  ## batch, vacabulary size\n            prob = torch.nn.functional.softmax(logits_from_pre_step, dim=-1)  ## batch, vocab_size\n            selected_index = torch.argmax(prob, dim=-1)  ## batch\n            # pred_tokens_id = prob[:, selected_index].unsqueeze(dim=-1)  ## batch , 1\n            pred_tokens_id = selected_index.unsqueeze(dim=-1)  ## batch, 1 ~~ this is the new token id for each sequence\n            \n            predict_logits.append(logits_from_pre_step)\n            ##############################################################################################\n            \n#           print(pred_tokens_id)\n#             print(labels[:,curlen])\n\n            #### prepare the new input, and the output for next round(step) ####################################\n            ####################################################################################################\n            #### random pick the next input\n            rnd = torch.tensor([random.random() for _ in range(batch_size)])\n            pick_answer = (rnd > 0.5).int()\n            pick_answer = pick_answer * unfinished_sentence\n            ### if has finished the sentence, then the label[k,cur_len] should be the -100, so cannot choose it\n            pick_answer = pick_answer.unsqueeze(dim=-1)\n            input_ids = (1-pick_answer) * pred_tokens_id + pick_answer * labels[:,curlen].unsqueeze(dim=-1)\n            \n#             print(pred_tokens_id)\n#             print(input_ids)\n            \n            \n            ##check print(pick_answer)\n            ##check print(input_ids)\n            \n            # input_ids = pred_tokens_id\n            #### \n\n            #### get new attention mask\n            \n            ##### all set to attention\n            #### new_attention_mask = torch.tensor([[1]] * batch_size, dtype=torch.int32)\n            \n            #### after one eof appear in prediction, only attented the first eof, other is mask\n            new_attention_mask = unfinished_sentence[:,None]\n            # print(new_attention_mask)\n            \n            attention_mask = torch.cat([attention_mask, new_attention_mask], dim=-1) \n            ####\n            \n            input_ids = input_ids.to(DEVICE)\n            attention_mask = attention_mask.to(DEVICE)\n            \n            outputs = self.transformer(input_ids=input_ids, attention_mask=attention_mask, past_key_values=past_key_values)\n            \n            input_ids = input_ids.cpu()\n            attention_mask = attention_mask.cpu()\n            ####################################################################################################\n\n            #### renew the past key value, logits ##############################################################\n            ####################################################################################################\n            next_last_hidden = outputs.last_hidden_state  ## (batch, 1, hidden_size)\n            logits = self.lm_head(next_last_hidden).cpu() ## (batch, 1, vocab_size)\n            last_hidden = torch.cat([last_hidden, next_last_hidden.cpu()], dim=1)\n            past_key_values = outputs.past_key_values\n            #### \n            ####################################################################################################\n    \n            curlen += 1\n            if curlen == should_pred_len:\n                this_peer_finished = True\n            else :\n                unfinished_sentence = unfinished_sentence * labels[:,curlen].ne(torch.tensor([-100]) )\n\n        ##############################################\n        predict_logits = torch.stack(predict_logits)\n        predict_logits = predict_logits.permute(1, 0, 2).contiguous() ## seq_len, batch, vocab_size -> batch, seq_len, vocab_size\n        return predict_logits\n            ","metadata":{"execution":{"iopub.status.busy":"2023-08-22T18:44:05.849827Z","iopub.execute_input":"2023-08-22T18:44:05.850271Z","iopub.status.idle":"2023-08-22T18:44:05.876649Z","shell.execute_reply.started":"2023-08-22T18:44:05.850237Z","shell.execute_reply":"2023-08-22T18:44:05.875636Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"model = MyModel()\n# model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\nmodel.to(DEVICE)\nmodel.config.pad_token_id = Padding_id\n\noptimizer = torch.optim.SGD(model.parameters(), lr=0.00002, momentum=0.5, nesterov = True)\n\nfor _ in range(5) :\n    myloss = 0\n\n    for data in dataloader:\n        input_id, attention_mask , label = data\n\n    #     input_id = input_id.to(DEVICE)\n    #     attention_mask = attention_mask.to(DEVICE)\n    #     label = label.to(DEVICE)\n\n        loss = model(input_ids = input_id, attention_mask = attention_mask, labels = label)\n#         print(loss)\n        \n        myloss += loss.item()\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    \n    print(myloss / len(ds))\n","metadata":{"execution":{"iopub.status.busy":"2023-08-22T18:44:19.411130Z","iopub.execute_input":"2023-08-22T18:44:19.411515Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0346ed996e7445aca8422edd50b859cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0157377c77f54129bb1261ae376a9c14"}},"metadata":{}},{"name":"stdout","text":"1378.26884496212\n884.2304399013519\n763.5755435675383\n","output_type":"stream"}]}]}